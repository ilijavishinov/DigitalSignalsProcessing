{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Why is sistematization important?\n",
    "\n",
    "The annotation files are not consistent between databases,\n",
    "and even within the cudb database itself.\n",
    "\n",
    "This was due to planning on combining multiple databases, but i opted for a different approach.\n",
    "\n",
    "The afdb samples and annotations are downsampled to 125hz because of big RAM requirements and longer training times.\n",
    "\n",
    "For example, in some annotation files the start of a VF episode is annotated by \"+, (VF\",\n",
    "and somewhere only by '\\[' for start and '\\]' for end.\n",
    "Also, in some cases the end of the vf episode is not annotated.\n",
    "\n",
    "In the other databases, all episodes start with \"+, (episode\",\n",
    "so the cudb files will be parsed so that they are consistent\n",
    "if more databases are used going forward.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "AFDB_HZ = 250\n",
    "AFDB_EPISODES = ['(N', '(AFIB', '(AFL', '(J']\n",
    "\n",
    "data_dir = 'data\\physionet_dbs\\\\afdb\\\\annotations'\n",
    "write_data_dir = 'data\\physionet_dbs\\\\afdb\\\\annotations_systemized_125hz'\n",
    "if not os.path.exists(write_data_dir):\n",
    "    os.makedirs(write_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04015.ann\n",
      "(15, 6)\n",
      "04043.ann\n",
      "(166, 6)\n",
      "04048.ann\n",
      "(15, 6)\n",
      "04126.ann\n",
      "(15, 6)\n",
      "04746.ann\n",
      "(11, 6)\n",
      "04908.ann\n",
      "(17, 6)\n",
      "04936.ann\n",
      "(73, 6)\n",
      "05091.ann\n",
      "(17, 6)\n",
      "05121.ann\n",
      "(42, 6)\n",
      "05261.ann\n",
      "(23, 6)\n",
      "06426.ann\n",
      "(55, 6)\n",
      "06453.ann\n",
      "(13, 6)\n",
      "06995.ann\n",
      "(11, 6)\n",
      "07162.ann\n",
      "(1, 6)\n",
      "07859.ann\n",
      "(1, 6)\n",
      "07879.ann\n",
      "(5, 6)\n",
      "07910.ann\n",
      "(10, 6)\n",
      "08215.ann\n",
      "(4, 6)\n",
      "08219.ann\n",
      "(79, 6)\n",
      "08378.ann\n",
      "(17, 6)\n",
      "08405.ann\n",
      "(4, 6)\n",
      "08434.ann\n",
      "(7, 6)\n",
      "08455.ann\n",
      "(4, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    print(str(file).replace('.txt',''))\n",
    "\n",
    "    dataset = pd.read_table(f'{data_dir}/{file}', header=None, index_col=False, engine='python', sep = '[\\s]{2,}')\n",
    "    print(dataset.shape)\n",
    "\n",
    "    # columns and dtypes\n",
    "    dataset.columns = ['timestamp','sample_idx', 'beat', 'misc_1', 'misc_2','episode']\n",
    "    dataset.drop(labels = ['timestamp', 'misc_1', 'misc_2'], axis = 1, inplace = True)\n",
    "    dataset['beat'] = dataset['beat'].astype(str)\n",
    "    dataset['episode'] = dataset['episode'].astype(str)\n",
    "\n",
    "    # so that 0s in sample_idx are not replaced by the following step\n",
    "    sample_idx_column = dataset['sample_idx']\n",
    "    dataset.drop(labels = ['sample_idx'], inplace = True, axis = 1)\n",
    "\n",
    "    # handling problematic parsing\n",
    "    dataset.replace({0: '', '0': ''}, inplace = True)\n",
    "    for episode_iter in AFDB_EPISODES:\n",
    "        dataset.replace({f'0\\t{episode_iter}': f'{episode_iter}'}, inplace = True)\n",
    "    dataset.replace({'': None}, inplace = True)\n",
    "\n",
    "    # recover sample_idx column\n",
    "    dataset.insert(0, 'sample_idx', sample_idx_column)\n",
    "    dataset['sample_idx'] = dataset['sample_idx'].astype('int32')\n",
    "\n",
    "    for row_idx, row in dataset.iterrows():\n",
    "        dataset.loc[row_idx, 'sample_idx'] = int(round(row['sample_idx']/2))\n",
    "\n",
    "    dataset.sort_values(by = ['sample_idx'], inplace = True)\n",
    "    dataset.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    dataset.to_csv(f'{write_data_dir}\\\\{str(file.replace(\".ann\",\"\"))}.csv', index = False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}