{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Extraction of clean episode signals\n",
    "\n",
    "The noise annotations in cudb are quite ambiguous, so extracting clean episode signals before\n",
    "creating the segments seems like a good idea which will simplify the further data engineering\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ann_data_dir = 'data\\physionet_dbs\\\\afdb\\\\annotations_systemized_125hz'\n",
    "samp_data_dir = 'data\\physionet_dbs\\\\afdb\\samples_125hz'\n",
    "write_data_dir = 'data\\physionet_dbs\\\\afdb\\\\uniclass_episode_signals_testing_125hz'\n",
    "\n",
    "if not os.path.exists(write_data_dir):\n",
    "    os.makedirs(write_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06426.csv\n",
      "06453.csv\n",
      "06995.csv\n",
      "07162.csv\n",
      "07859.csv\n",
      "07879.csv\n",
      "07910.csv\n",
      "08215.csv\n",
      "08219.csv\n",
      "08378.csv\n",
      "08405.csv\n",
      "08434.csv\n",
      "08455.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(ann_data_dir):\n",
    "\n",
    "    file = str(file)\n",
    "\n",
    "    if file in [ '04015.csv','04043.csv','04048.csv','04126.csv','04746.csv',\n",
    "                 '04908.csv','04936.csv','05091.csv','05121.csv','05261.csv']:\n",
    "        continue\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    ann_file = pd.read_csv(f'{ann_data_dir}\\\\{file}')\n",
    "    samp_file = pd.read_csv(f'{samp_data_dir}\\\\{file}')\n",
    "    samp_file.columns = ['sample_idx', 'ecg']\n",
    "\n",
    "    # beat annotations are irrelevant, so they are dismissed\n",
    "    ann_file = ann_file[~ann_file['episode'].isna()].reset_index(drop = True)\n",
    "\n",
    "    # the current episode that the segments belong to, and is kept if noise comes as an episode annotation\n",
    "    ongoing_episode = None\n",
    "\n",
    "    # iterating episodes\n",
    "    for ann_idx, ann_row in ann_file.iterrows():\n",
    "\n",
    "        # if last noise annotation, assume the rest of the signal is fine and noiseless\n",
    "        if ann_row['episode'] == 'NOISE' and ann_idx == ann_file.shape[0] - 1:\n",
    "            episode = ongoing_episode\n",
    "            episode_start_sample = ann_row['sample_idx'] + 1\n",
    "        # if there are noise anns following the current noise ann, because of ambiguity, dismiss the signal\n",
    "        elif ann_row['episode'] == 'NOISE' and ann_file.iloc[ann_idx + 1]['episode'] == 'NOISE':\n",
    "            episode = ongoing_episode\n",
    "            episode_start_sample = ann_row['sample_idx'] + 1\n",
    "        elif ann_row['episode'] == 'NOISE' and ann_file.iloc[ann_idx + 1]['episode'] != 'NOISE':\n",
    "            continue\n",
    "        # in the normal case when a rhythm episode begins\n",
    "        else:\n",
    "            episode = ann_row['episode']\n",
    "            ongoing_episode = ann_row['episode']\n",
    "            episode_start_sample = ann_row['sample_idx']\n",
    "\n",
    "        # if last episode, go to end of file, otherwise end is the start of next episode\n",
    "        if ann_idx == ann_file.shape[0] - 1:\n",
    "            episode_end_sample = samp_file.iloc[-1]['sample_idx']\n",
    "        else:\n",
    "            episode_end_sample = ann_file.iloc[ann_idx + 1]['sample_idx'] - 1\n",
    "\n",
    "        clean_episode_signal = samp_file[\n",
    "            (samp_file['sample_idx'] >= episode_start_sample) &\n",
    "            (samp_file['sample_idx'] <= episode_end_sample)\n",
    "        ]\n",
    "\n",
    "        clean_episode_signal.to_csv(\n",
    "                f'{write_data_dir}\\\\'\n",
    "                f'{file.replace(\".csv\",\"\")}_'\n",
    "                f'{episode.replace(\"(\",\"\")}_'\n",
    "                f'{ann_idx}.csv',\n",
    "                index = False\n",
    "        )\n",
    "\n",
    "        # break\n",
    "    #\n",
    "    # break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%reset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}